{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- Parameters uit Opdracht 2 ---\n",
    "ALPHA = 5.0\n",
    "BETA = 0.1\n",
    "AVG_TRIPS_PER_RESIDENT_PER_DAY = 0.8\n",
    "PEAK_HOUR_SHARE = 0.1\n",
    "\n",
    "POPULATION_CATCHMENT_AREA = 2185000\n",
    "print(f\"Gekozen populatie: {POPULATION_CATCHMENT_AREA}\")\n",
    "\n",
    "# --- Paden definiëren ---\n",
    "# Aanname: Dit notebook (code_assignment_2.ipynb) staat in de map 'csv_assignment2'.\n",
    "# De input CSV-bestanden (gegenereerd door A1) staan in een zustermap 'csv_assignment1'.\n",
    "# De output OD-matrix wordt in de huidige map ('csv_assignment2') opgeslagen.\n",
    "\n",
    "# Input pad voor de CSV-bestanden gegenereerd door A1\n",
    "# Ga één niveau omhoog vanuit 'csv_assignment2' naar de project root, dan naar 'csv_assignment1'\n",
    "csv_input_folder_a1 = os.path.join(\"..\", \"csv_assignment1\")\n",
    "l_space_nodes_file = os.path.join(csv_input_folder_a1, \"montreal_L_space_nodes.csv\")\n",
    "l_space_edges_file = os.path.join(csv_input_folder_a1, \"montreal_L_space_edges.csv\")\n",
    "\n",
    "# Output pad voor de OD-matrix van A2 (huidige map)\n",
    "csv_output_folder_a2 = os.path.join(\"..\", \"csv_assignment2\")\n",
    "os.makedirs(csv_output_folder_a2, exist_ok=True)\n",
    "\n",
    "# --- Stap 1: Maak een Origin-Destination (OD) matrix ---\n",
    "print(\"\\n--- START STAP 1: OD Matrix Creatie (vanuit CSVs) ---\")\n",
    "\n",
    "# 1. Laad L-space graaf van Opdracht 1 (uit CSV-bestanden)\n",
    "try:\n",
    "    df_nodes_L = pd.read_csv(l_space_nodes_file)\n",
    "    df_edges_L = pd.read_csv(l_space_edges_file)\n",
    "    print(f\"\\n1. '{l_space_nodes_file}' en '{l_space_edges_file}' succesvol geladen.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"FOUT: CSV-bestanden niet gevonden in '{os.path.abspath(csv_input_folder_a1)}'.\")\n",
    "    print(\"Zorg dat het script 'csv_assignment1.py' (of equivalent) is uitgevoerd en de bestanden daar staan.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"FOUT bij het laden van CSV-bestanden: {e}\")\n",
    "    exit()\n",
    "\n",
    "G_Lspace = nx.Graph()\n",
    "# Voeg nodes toe\n",
    "for _, row in df_nodes_L.iterrows():\n",
    "    node_id = row['node']\n",
    "    attrs = {k: v for k, v in row.drop('node').to_dict().items() if pd.notna(v)}\n",
    "    G_Lspace.add_node(node_id, **attrs)\n",
    "\n",
    "# Voeg edges toe\n",
    "weight_col_in_csv = 'duration_avg'\n",
    "if weight_col_in_csv not in df_edges_L.columns:\n",
    "    if 'weight' in df_edges_L.columns:\n",
    "        print(f\"   WAARSCHUWING: Kolom '{weight_col_in_csv}' niet in edges CSV, '{'weight'}' wel. Gebruik '{'weight'}'.\")\n",
    "        weight_col_in_csv = 'weight'\n",
    "    else:\n",
    "        print(f\"   FOUT: Kolom '{weight_col_in_csv}' (of 'weight') niet gevonden in '{l_space_edges_file}'.\")\n",
    "        exit()\n",
    "\n",
    "for _, row in df_edges_L.iterrows():\n",
    "    u, v = row['u'], row['v']\n",
    "    attrs = {k: val for k, val in row.drop(['u', 'v']).to_dict().items() if pd.notna(val)}\n",
    "    if weight_col_in_csv in attrs:\n",
    "        try:\n",
    "            attrs[weight_col_in_csv] = float(attrs[weight_col_in_csv])\n",
    "        except ValueError:\n",
    "            print(f\"   WAARSCHUWING: Kon gewicht '{attrs[weight_col_in_csv]}' voor edge ({u}-{v}) niet converteren.\")\n",
    "    G_Lspace.add_edge(u, v, **attrs)\n",
    "\n",
    "stations = sorted(list(G_Lspace.nodes()))\n",
    "num_stations = len(stations)\n",
    "print(f\"   L-space graaf gereconstrueerd. Aantal stations: {num_stations}, Aantal edges: {G_Lspace.number_of_edges()}\")\n",
    "if num_stations == 0 or G_Lspace.number_of_edges() == 0:\n",
    "    print(\"FOUT: Graaf is leeg na reconstructie.\")\n",
    "    exit()\n",
    "print(f\"   Voorbeeld stations (eerste 5 gesorteerd): {stations[:5]}\")\n",
    "\n",
    "weight_attribute_closeness = weight_col_in_csv\n",
    "first_edge_data = next(iter(G_Lspace.edges(data=True)), (None, None, {}))[2]\n",
    "if weight_attribute_closeness not in first_edge_data or not isinstance(first_edge_data.get(weight_attribute_closeness), (int, float)):\n",
    "    print(f\"   FOUT: Attribuut '{weight_attribute_closeness}' niet correct (numeriek) gevonden op edges na reconstructie.\")\n",
    "    # exit() # Overweeg exit\n",
    "\n",
    "# --- REST VAN DE CODE (Stap 2 t/m 9) BLIJFT HETZELFDE ALS IN HET VORIGE ANTWOORD ---\n",
    "# (Closeness, Q, q_i, t_ij, f_ij, X_OD berekeningen en opslaan)\n",
    "\n",
    "# 2. Bereken Closeness Centrality (c_i) ...\n",
    "closeness_centralities_dict = nx.closeness_centrality(G_Lspace, distance=weight_attribute_closeness)\n",
    "closeness_centralities = pd.Series(closeness_centralities_dict).reindex(stations)\n",
    "print(f\"\\n2. Closeness Centralities (c_i) berekend voor {len(closeness_centralities)} stations.\")\n",
    "print(\"   Voorbeeld c_i (eerste 5 stations):\\n\", closeness_centralities.head())\n",
    "print(f\"   Min c_i: {closeness_centralities.min():.4f}, Max c_i: {closeness_centralities.max():.4f}, Gem c_i: {closeness_centralities.mean():.4f}\")\n",
    "\n",
    "# 3. Bereken totaal aantal trips (Q) in de spits (8-9 AM)\n",
    "Q_total_trips = POPULATION_CATCHMENT_AREA * AVG_TRIPS_PER_RESIDENT_PER_DAY * PEAK_HOUR_SHARE\n",
    "print(f\"\\n3. Totaal aantal OV-trips in de spits (Q): {Q_total_trips:.2f}\")\n",
    "\n",
    "# 4. Bereken trip producties per station (q_i)\n",
    "sum_closeness = closeness_centralities.sum()\n",
    "if sum_closeness == 0:\n",
    "    print(\"FOUT: Som van closeness centralities is nul. Kan q_i niet berekenen.\")\n",
    "    exit()\n",
    "q_productions = (closeness_centralities / sum_closeness) * Q_total_trips\n",
    "print(f\"\\n4. Trip Producties (q_i) berekend voor {len(q_productions)} stations.\")\n",
    "print(\"   Voorbeeld q_i (eerste 5 stations):\\n\", q_productions.head())\n",
    "print(f\"   Min q_i: {q_productions.min():.2f}, Max q_i: {q_productions.max():.2f}, Gem q_i: {q_productions.mean():.2f}\")\n",
    "print(f\"   Som van q_i: {q_productions.sum():.2f} (zou gelijk moeten zijn aan Q = {Q_total_trips:.2f})\")\n",
    "\n",
    "# 5. Bereken all-pairs shortest In-Vehicle Travel Time (t_ij) in MINUTEN\n",
    "G_Lspace_min_ivtt = G_Lspace.copy()\n",
    "weight_attribute_ivtt_seconds_from_csv = weight_attribute_closeness\n",
    "weight_attribute_ivtt_minutes = 'ivtt_min'\n",
    "conversion_count = 0\n",
    "missing_weight_count = 0\n",
    "for u, v, data in G_Lspace_min_ivtt.edges(data=True):\n",
    "    ivtt_sec_value = data.get(weight_attribute_ivtt_seconds_from_csv)\n",
    "    if ivtt_sec_value is not None:\n",
    "        try:\n",
    "            data[weight_attribute_ivtt_minutes] = float(ivtt_sec_value) / 60.0\n",
    "            conversion_count += 1\n",
    "        except (ValueError, TypeError):\n",
    "            data[weight_attribute_ivtt_minutes] = float('inf')\n",
    "            missing_weight_count += 1\n",
    "            print(f\"   WAARSCHUWING: Kon IVTT waarde '{ivtt_sec_value}' voor edge ({u}-{v}) niet converteren. Gezet op oneindig.\")\n",
    "    else:\n",
    "        data[weight_attribute_ivtt_minutes] = float('inf')\n",
    "        missing_weight_count +=1\n",
    "if missing_weight_count > 0:\n",
    "    print(f\"   LET OP: {missing_weight_count} edges misten een geldig gewichtsattribuut voor IVTT conversie.\")\n",
    "print(f\"   IVTT geconverteerd naar minuten voor {conversion_count} edges.\")\n",
    "\n",
    "shortest_paths_ivtt_dict = dict(nx.all_pairs_dijkstra_path_length(G_Lspace_min_ivtt, weight=weight_attribute_ivtt_minutes))\n",
    "t_ij_matrix = pd.DataFrame(index=stations, columns=stations, dtype=float)\n",
    "for origin_station in stations:\n",
    "    if origin_station in shortest_paths_ivtt_dict:\n",
    "        for dest_station in stations:\n",
    "            t_ij_matrix.loc[origin_station, dest_station] = shortest_paths_ivtt_dict[origin_station].get(dest_station, float('inf'))\n",
    "    else:\n",
    "        t_ij_matrix.loc[origin_station, :] = float('inf')\n",
    "    t_ij_matrix.loc[origin_station, origin_station] = 0.0\n",
    "print(f\"\\n5. In-vehicle reistijd matrix (t_ij) in minuten berekend ({t_ij_matrix.shape[0]}x{t_ij_matrix.shape[1]}).\")\n",
    "if num_stations >= 5: print(\"   Voorbeeld t_ij matrix (eerste 5 stations, eerste 5 bestemmingen):\\n\", t_ij_matrix.loc[stations[:5], stations[:5]])\n",
    "else: print(\"   Voorbeeld t_ij matrix:\\n\", t_ij_matrix)\n",
    "finite_t_ij_values = t_ij_matrix.values[np.isfinite(t_ij_matrix.values) & (t_ij_matrix.values > 0)]\n",
    "if len(finite_t_ij_values) > 0: print(f\"   Min t_ij (positief, eindig): {np.min(finite_t_ij_values):.2f} min, Max t_ij (eindig): {np.max(finite_t_ij_values):.2f} min\")\n",
    "else: print(\"   WAARSCHUWING: Geen positieve, eindige t_ij waarden gevonden.\")\n",
    "\n",
    "# 6. Bereken Impedantie Matrix (f_ij)\n",
    "f_ij_matrix = pd.DataFrame(index=stations, columns=stations, dtype=float)\n",
    "for i in stations:\n",
    "    for j in stations:\n",
    "        if i == j: f_ij_matrix.loc[i, j] = 0.0\n",
    "        else:\n",
    "            current_t_ij = t_ij_matrix.loc[i, j]\n",
    "            if current_t_ij == float('inf'): f_ij_matrix.loc[i, j] = 0.0\n",
    "            else: f_ij_matrix.loc[i, j] = ALPHA * np.exp(-BETA * current_t_ij)\n",
    "print(f\"\\n6. Impedantie matrix (f_ij) berekend ({f_ij_matrix.shape[0]}x{f_ij_matrix.shape[1]}).\")\n",
    "if num_stations >= 5: print(\"   Voorbeeld f_ij matrix (eerste 5 stations, eerste 5 bestemmingen):\\n\", f_ij_matrix.loc[stations[:5], stations[:5]])\n",
    "else: print(\"   Voorbeeld f_ij matrix:\\n\", f_ij_matrix)\n",
    "non_zero_f_ij = f_ij_matrix.values[f_ij_matrix.values > 0];\n",
    "if len(non_zero_f_ij) > 0: print(f\"   Min f_ij (positief): {non_zero_f_ij.min():.4f}, Max f_ij: {non_zero_f_ij.max():.4f}, Gem f_ij (positief): {non_zero_f_ij.mean():.4f}\")\n",
    "else: print(\"   WAARSCHUWING: Alle f_ij waarden zijn nul.\")\n",
    "\n",
    "# 7. Bereken de noemers voor x_ij\n",
    "sum_qs_fis_for_origin_i = pd.Series(index=stations, dtype=float)\n",
    "for i in stations:\n",
    "    current_denominator_sum = 0.0\n",
    "    for s in stations:\n",
    "        if i == s: continue\n",
    "        current_denominator_sum += q_productions[s] * f_ij_matrix.loc[i, s]\n",
    "    sum_qs_fis_for_origin_i[i] = current_denominator_sum\n",
    "print(f\"\\n7. Noemer termen (Σ_s q_s * f_is) berekend voor {len(sum_qs_fis_for_origin_i)} origins.\")\n",
    "print(\"   Voorbeeld noemer termen (eerste 5 stations):\\n\", sum_qs_fis_for_origin_i.head())\n",
    "print(f\"   Min noemer: {sum_qs_fis_for_origin_i.min():.2f}, Max noemer: {sum_qs_fis_for_origin_i.max():.2f}\")\n",
    "\n",
    "# 8. Bereken de OD Matrix (x_ij)\n",
    "X_OD_matrix = pd.DataFrame(index=stations, columns=stations, dtype=float)\n",
    "for i in stations:\n",
    "    for j in stations:\n",
    "        if i == j: X_OD_matrix.loc[i, j] = 0.0\n",
    "        else:\n",
    "            q_j_attraction = q_productions[j]; f_ij_value = f_ij_matrix.loc[i, j]\n",
    "            numerator = q_j_attraction * f_ij_value; denominator = sum_qs_fis_for_origin_i[i]\n",
    "            if denominator == 0 or np.isclose(denominator, 0): X_OD_matrix.loc[i, j] = 0.0\n",
    "            else: X_OD_matrix.loc[i, j] = q_productions[i] * (numerator / denominator)\n",
    "print(f\"\\n8. OD Matrix (x_ij) berekend ({X_OD_matrix.shape[0]}x{X_OD_matrix.shape[1]}).\")\n",
    "if num_stations >= 5: print(\"   Voorbeeld OD matrix (eerste 5 stations, eerste 5 bestemmingen):\\n\", X_OD_matrix.loc[stations[:5], stations[:5]])\n",
    "else: print(\"   Voorbeeld OD matrix:\\n\", X_OD_matrix)\n",
    "print(f\"   Min x_ij: {X_OD_matrix.values.min():.2f}, Max x_ij: {X_OD_matrix.values.max():.2f}, Gem x_ij: {X_OD_matrix.values.mean():.2f}\")\n",
    "total_sum_x_ij = X_OD_matrix.values.sum()\n",
    "print(f\"   Totale som alle x_ij waarden: {total_sum_x_ij:.2f} (zou gelijk moeten zijn aan Q = {Q_total_trips:.2f})\")\n",
    "if not np.isclose(total_sum_x_ij, Q_total_trips, rtol=1e-3): print(f\"   WAARSCHUWING: Totale som x_ij ({total_sum_x_ij:.2f}) wijkt af van Q ({Q_total_trips:.2f}).\")\n",
    "\n",
    "# Optionele verificatie\n",
    "row_sums_X_OD = X_OD_matrix.sum(axis=1)\n",
    "verification_df = pd.DataFrame({'q_i': q_productions, 'X_OD_row_sum': row_sums_X_OD})\n",
    "verification_df['difference'] = verification_df['q_i'] - verification_df['X_OD_row_sum']\n",
    "verification_df = verification_df.reindex(stations)\n",
    "print(\"\\nVerificatie van OD matrix (rij sommen vs q_i):\")\n",
    "print(verification_df.head(10))\n",
    "print(f\"   Maximale absolute afwijking in verificatie: {verification_df['difference'].abs().max():.6e}\")\n",
    "print(f\"   Gemiddelde absolute afwijking: {verification_df['difference'].abs().mean():.6e}\")\n",
    "\n",
    "# 9. Sla de OD matrix op als .csv in de huidige map ('csv_assignment2')\n",
    "output_od_filename = os.path.join(csv_output_folder_a2, f\"OD_Matrix_Montreal{int(POPULATION_CATCHMENT_AREA/1000)}k.csv\")\n",
    "X_OD_matrix.to_csv(output_od_filename)\n",
    "print(f\"\\n9. OD Matrix opgeslagen als '{os.path.abspath(output_od_filename)}'\") # Print absolute pad\n",
    "\n",
    "print(\"\\n--- Stap 1 Voltooid ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airline_planning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
